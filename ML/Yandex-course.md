# Курс по нейросетям от Яндекс

## Как работают нейросети

Нейросеть — это компьютерная программа! с помощью математических вычислений, вычисляет, что написать в ответ.
Когда мы отправляем сообщение, нейросеть обрабатывает текст по кусочкам — токенам.

Когда нейросеть «читает» слово, она переводит его в набор чисел — это и есть вектор
Затем нейросеть формирует по каждому токену его «вектор смысла» — он называется эмбеддингом.

Дальше нейросеть из векторов отдельных слов собирает общий вектор — смысл целого предложения или запроса.
Затем на основе смысла всего предложения нейросеть предсказывает следующее слово.
Это может быть как самое вероятное слово, так и случайно выбранное среди наиболее вероятных.
Так, дописывая слово за словом, нейросеть генерирует весь ответ на наш первоначальный запрос.

## Опасность галлюцинаций

Ответы нейросети надо обязательно перепроверять!

## Диалог и обучение

Нейросеть никогда не дообучается во время общения: просто для генерации каждого следующего ответа ей на вход подаётся весь предшествующий диалог, включая реплики пользователя и её собственные ответы.

## Что такое контекст

Когда мы разговариваем с нейросетью, она записывает весь наш диалог и при ответе на следующие вопросы учитывает сказанное ранее. Такой диалог называется контекстом, и у любой нейросети его размер ограничен.
длинная книга просто не влезет в контекст диалога.

Не работают с длинными текстами — отправлять такие тексты нужно по частям.
Плохо считают — лучше использовать калькулятор или перепроверять.
Могут ошибаться и галлюцинировать. Необходимо перепроверять в других источниках.

### =================================================================

# Основы промптинга

## Составляющие промпта для обучающего примера

При создании обучающих примеров важно правильно сформулировать **промпт** — инструкцию, которая направляет модель на выполнение задачи. Хороший промпт должен быть чётким, структурированным и включать все необходимые элементы для получения ожидаемого результата.

## Основные компоненты промпта

### 1. **Роль (Role)**

Определение роли, которую должен играть ИИ.

> Пример: _"Ты — опытный программист, специализирующийся на Python."_

### 2. **Задача (Task)**

Чёткое описание того, что нужно сделать.

> Пример: _"Напиши функцию на Python, которая проверяет, является ли строка палиндромом."_

### 3. **Контекст (Context)**

Тема, контекст: с чем связана задача
Дополнительная информация, помогающая понять задачу.
Чем более чётко ты сформулируешь контекст, тем лучше.

> Пример: _"Палиндром — это слово или фраза, которые читаются одинаково слева направо и справа налево, например 'шалаш' или 'А роза упала на лапу Азора'."_  
> _"Учитывай пробелы, знаки препинания и регистр."_

### 4. **Формат ответа (Output format)**

Указание, в каком виде должен быть представлен результат.
или
Аудитория: для кого

> Пример: _"Верни только код функции на Python без дополнительных пояснений."_  
> Или: _"Предоставь ответ в формате Markdown с пояснениями."_
> Отвечай, чтобы понял школьник.

### 5. **Примеры (Few-shot examples) (опционально)**

Образцы входных и выходных данных, особенно полезны в few-shot обучении.

> Пример:  
> Ввод: `"А роза упала на лапу Азора"` → Вывод: `True`  
> Ввод: `"привет"` → Вывод: `False`

### 6. **Ограничения и требования (Constraints)**

Ограничения по стилю, длине, библиотекам, безопасности и т.д.

> Пример: _"Не используй встроенные функции разворота строки, такие как `[::-1]`."_  
> _"Код должен быть совместим с Python 3.8+."_

---

Тебе необязательно всегда писать идеальные формулировки, но чем понятнее ты объяснишь, чего хочешь, тем точнее и полезнее сработает нейросеть.

## Пример полного промпта

```text
Ты — опытный программист на Python.
Напиши функцию `is_palindrome(s)`, которая проверяет, является ли строка палиндромом.
Учитывай, что нужно игнорировать пробелы, знаки препинания и регистр букв.
Примеры:
- "А роза упала на лапу Азора" → True
- "шалаш" → True
- "привет" → False

Не используй `[::-1]`.
Верни только код функции в формате Python, без тестов и пояснений.

```

# Память и контекст

Теперь подробнее рассмотрим понятия «память» и «контекст». Это разные вещи, так что важно зафиксировать различия между ними.

Контекст
Ты уже знаешь, что нейросеть помнит контекст беседы, потому что на каждом шагу ей подаётся вся история переписки. Собственно то, что подаётся на вход нейросети, часто так и называют — контекстом. И длина контекста, с которой может работать нейросеть, ограничена.

не может использовать эти знания, каждый раз не перечитывая этот текст заново.
Внимания нейросети хватает на то, чтобы видеть последние несколько десятков тысяч токенов в каждой переписке.

Память
Память есть не у всех нейросетей. Например, если в переписке с ChatGPT ты напишешь: «Меня зовут Вася, я люблю помидоры», нейросеть может сохранить эту информацию. Тогда в новых диалогах она будет помнить твоё имя и предпочтения.
Но важно понимать:
Что именно запомнить, решает сама нейросеть. Пользователь не управляет этим напрямую.
Не у всех моделей есть память. Многие работают только с текущим диалогом.
Нельзя полагаться только на память. Она может забыть или не сохранить данные. Поэтому всё, что критически важно для задачи, лучше указывать прямо в промпте.


# Три техники промптинга
Все приведённые выше промпты выполнены в одной технике — Zero-Shot Prompting (промпт без примеров):
ставим задачу («сделай конспект», «перепиши файл»);
указываем формат и стиль;
не приводим примеры, как должен выглядеть идеальный результат.

А есть ещё такие техники: 

One-Shot Prompting (промпт с одним примером);
Итак, в технике Zero-Shot GPT старается, как умеет. Иногда угадывает, иногда — не очень.
А теперь представь: ты говоришь нейросети не просто «Сделай», а «Сделай вот так, как я показываю в примере». Это и есть One-Shot Prompting.

Few-Shot Prompting (промпт с несколькими примерами).
Запрос с одним примером даёт результат лучше, чем без примеров. Но если задача сложная или ответ должен быть особенно точным, одного примера бывает мало. 
Это как показать дизайнеру не одно фото платья, а три-четыре, поясняя: «Вот тут нравится цвет, тут — фасон, а здесь — как сидит на фигуре».
GPT воспринимает примеры похожим образом: не копирует смысл, а схватывает форму ответа.